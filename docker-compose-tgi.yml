# Docker Compose for Qwen 2.5 using HuggingFace TGI (High Performance)
version: '3.8'

services:
  qwen-tgi:
    image: ghcr.io/huggingface/text-generation-inference:2.0
    container_name: qwen-tgi
    ports:
      - "8080:80"
    volumes:
      - hf_cache:/data
    environment:
      - MODEL_ID=Qwen/Qwen2.5-7B-Instruct
      - PORT=80
      - CUDA_VISIBLE_DEVICES=0
    command: >
      --model-id Qwen/Qwen2.5-7B-Instruct
      --max-total-tokens 4096
      --max-input-length 3072
      --max-batch-prefill-tokens 4096
    shm_size: 1g
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

volumes:
  hf_cache:
